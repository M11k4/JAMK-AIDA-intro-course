{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Data sources\n",
    "- All files used in this exercise can be found under the Exercises/data_files directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "1 Use gamedata.json for this task. This file contains information of games sold through Steam. Parse out the following information from the data:\n",
    "- TOP 3 highest metacritic score. Present results using the following format: *Title* has metacritic score of *Score* (for example)\n",
    "- Games with price discount being 90 % or more. Present results using the following format: *Title* | Discount: *Savings* (for example Metal Gear Solid V: Ground Zeroes | Discount: 90.090090)\n",
    "- Games having metacritic score higher than steam score. Present results using the following format: *Title* has metacritic score of *MetacriticScore* and steam score of *SteamRatingPercent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars: Knights of the Old Republic has a Metacritic score of 93.\n",
      "Metal Gear Solid V: The Phantom Pain has a Metacritic score of 91.\n",
      "Bayonetta has a Metacritic score of 90.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def bestremainingscore(ghe):\n",
    "        tops = (0,0)\n",
    "        for k in ghe:\n",
    "            #print(int(k[1])+100*tops[1])\n",
    "            if int(k[1]) > int(tops[1]):\n",
    "                tops = k\n",
    "        return tops\n",
    "\n",
    "with open('data_files/gamedata.json') as gamedata:\n",
    "    gdata = json.load(gamedata)\n",
    "    \n",
    "    topandall = []\n",
    "    \n",
    "    for i in gdata:\n",
    "        topandall.append((i['title'],i['metacriticScore']))\n",
    "                \n",
    "    # print(topandall)\n",
    "\n",
    "    topscore1= bestremainingscore(topandall)\n",
    "    topandall.remove(topscore1)\n",
    "    topscore2= bestremainingscore(topandall)\n",
    "    topandall.remove(topscore2)\n",
    "    topscore3= bestremainingscore(topandall)\n",
    "    topandall.remove(topscore3)\n",
    "    \n",
    "    \n",
    "    print(topscore1[0] + \" has a Metacritic score of \" + topscore1[1] + \".\" )\n",
    "    print(topscore2[0] + \" has a Metacritic score of \" + topscore2[1] + \".\" )\n",
    "    print(topscore3[0] + \" has a Metacritic score of \" + topscore3[1] + \".\" )    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "2 Use earthquakes.csv for this task. This file contains information about earthquakes recorded between 1965 and 2016. Earthquake magnitude value describes how strong the earthquake is. Magnitude information can be categorized like presented in the table below (*Source: http://www.geo.mtu.edu/UPSeis/magnitude.html*).\n",
    "\n",
    "| Magnitude      | Class | Effects |\n",
    "|----------------|-------|---------|\n",
    "| 2.4 or less    | Minor | Usually not felt, but can be recorded by seismograph. |\n",
    "| 2.5 to 5.4     | Light | Often felt, but only causes minor damage. |\n",
    "| 5.5 to 6.0     | Moderate | Slight damage to buildings and other structures. |\n",
    "| 6.1 to 6.9     | Strong | May cause a lot of damage in very populated areas. |\n",
    "| 7.0 to 7.9     | Major | Major earthquake. Serious damage. |\n",
    "| 8.0 or greater | Great | Great earthquake. Can totally destroy communities near the epicenter. |\n",
    "\n",
    "Count how many earthquakes have occurred in each class.\n",
    "\n",
    "<b style=\"color:red;\">Notice:</b> The first value has been modified to be 2.4 or less compared to the original source (has been 2.5 or less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 17639, 5035, 698, 40]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "quakes_csv_pandas = pd.read_csv(\"data_files/earthquakes.csv\",delimiter=\",\")\n",
    "#quakes_csv_pandas\n",
    "\n",
    "quakeclasscount = [0,0,0,0,0,0]\n",
    "\n",
    "for i in quakes_csv_pandas.loc[:,\"Magnitude\"]:\n",
    "    if i < 2.5:\n",
    "        quakeclasscount[0] += 1\n",
    "    elif i < 5.5:\n",
    "        quakeclasscount[1] += 1\n",
    "    elif i < 6.1:\n",
    "        quakeclasscount[2] += 1\n",
    "    elif i < 7.0:\n",
    "        quakeclasscount[3] += 1\n",
    "    elif i < 8.0:\n",
    "        quakeclasscount[4] += 1\n",
    "    elif i >= 8.0:\n",
    "        quakeclasscount[5] += 1\n",
    "    else:\n",
    "        print(\"something wasn't a comparable number\")\n",
    "\n",
    "print(quakeclasscount)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Use netflix_titles.xml for this task. This file contains information about Netflix movies and TV shows. **Important:** Movies have duration presented in minutes while TV shows have duration presented in amount of seasons! Parse out the following information from the data:\n",
    "- Movies released in 2017\n",
    "- TV show and movie amount (present both counts in separate lines)\n",
    "- Movies with a length between 15 and 20 minutes (values 15 and 20 included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 744 movies released in 2017 found in the data.\n",
      "The data contains 5377 movies.\n",
      "The data contains 2410 TV shows.\n",
      "Out of all the movies, 11 have a duration between 15 and 20 minutes.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as e\n",
    "#import pandas as pd\n",
    "\n",
    "tree = e.parse(\"data_files/netflix_titles.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "watchable_collection = []\n",
    "\n",
    "titles = []\n",
    "for i in root[0]:\n",
    "    titles.append(i.tag)\n",
    "#print(titles)\n",
    "\n",
    "for elem in root:\n",
    "    watchable = {}\n",
    "    for subelemnum in range(len(elem)):\n",
    "        watchable.update({titles[subelemnum]: elem[subelemnum].text})\n",
    "    watchable_collection.append(watchable)\n",
    "#print(watchable_collection[:][ (watchable_collection[\"type\"] == 'Movie') & (watchable_collection[\"release_year\"] == 2017) ])\n",
    "\n",
    "#print(watchable_collection)\n",
    "\n",
    "watchable_collection_filtered = []\n",
    "\n",
    "for i in watchable_collection:\n",
    "    if ( i[\"type\"] == 'Movie') and ( int(i[\"release_year\"]) == 2017 ):\n",
    "        watchable_collection_filtered.append(i)\n",
    "        \n",
    "print('There are ' + str(len(watchable_collection_filtered)) + ' movies released in 2017 found in the data.')\n",
    "#print(watchable_collection_filtered[0:5])\n",
    "\n",
    "countmovies = 0\n",
    "countshows = 0\n",
    "countshortmovies = 0\n",
    "\n",
    "for i in watchable_collection:\n",
    "    if (i[\"type\"] == 'Movie'):\n",
    "        countmovies += 1\n",
    "    elif (i[\"type\"] == 'TV Show'):\n",
    "        countshows += 1\n",
    "        \n",
    "print('The data contains ' + str(countmovies) + ' movies.')\n",
    "print('The data contains ' + str(countshows) + ' TV shows.')\n",
    "\n",
    "for i in watchable_collection:\n",
    "    if ( i[\"type\"] == 'Movie'):        \n",
    "        dur = int(i[\"duration\"][:-4])\n",
    "        if (15 <= dur) & (dur <= 20):\n",
    "            countshortmovies +=1\n",
    "\n",
    "print('Out of all the movies, ' + str(countshortmovies) + ' have a duration between 15 and 20 minutes.')\n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Use the following Rest API for this task: https://tie.digitraffic.fi/api/v1/data/weather-data. Calculate the average for air temperature (ILMA) and humidity (ILMAN_KOSTEUS) values using two decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average temperature measured at 496 weather stations was -0.51 °C.\n",
      "The average air humidity measured at 490 weather stations was 91.65 %.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "endpoint = \"/facts\"\n",
    "user_id = \"5894af975cdc7400113ef7f9\"\n",
    "url = \"https://tie.digitraffic.fi/api/v1/data/weather-data\".format(endpoint, user_id)\n",
    "\n",
    "req = requests.get(url=url)\n",
    "\n",
    "#req.status_code\n",
    "\n",
    "weather_data = req.json()\n",
    "#weather_data\n",
    "\n",
    "howmanyILMAvaluesfound = 0\n",
    "howmanyKOSTEUSvaluesfound = 0\n",
    "sumofILMAvalues = 0.0\n",
    "sumofKOSTEUSvalues = 0.0\n",
    "\n",
    "#weather_data_sensorValues\n",
    "\n",
    "#weather_data.keys() -> dict_keys(['dataUpdatedTime', 'weatherStations'])\n",
    "#weather_data[\"weatherStations\"][2].keys() -> dict_keys(['id', 'measuredTime', 'sensorValues'])\n",
    "\n",
    "howmanystations= len(weather_data[\"weatherStations\"])\n",
    "\n",
    "for i in weather_data[\"weatherStations\"][2][\"sensorValues\"]:\n",
    "    if i[\"name\"] == 'ILMA':\n",
    "        #print(i)\n",
    "        break\n",
    "        \n",
    "for i in weather_data[\"weatherStations\"]:\n",
    "    for j in i[\"sensorValues\"]:\n",
    "        if j[\"name\"] == 'ILMA':\n",
    "            #print(j[\"sensorValue\"])\n",
    "            howmanyILMAvaluesfound += 1\n",
    "            sumofILMAvalues += j[\"sensorValue\"]\n",
    "        elif j[\"name\"] == 'ILMAN_KOSTEUS':\n",
    "            #print(j[\"sensorValue\"])\n",
    "            howmanyKOSTEUSvaluesfound += 1\n",
    "            sumofKOSTEUSvalues += j[\"sensorValue\"]\n",
    "        \n",
    "#print( howmanyILMAvaluesfound , sumofILMAvalues , sumofILMAvalues / howmanyILMAvaluesfound)\n",
    "\n",
    "print( 'The average temperature measured at ' + str(howmanyILMAvaluesfound) + ' weather stations was '\n",
    "     +  str(round(sumofILMAvalues / howmanyILMAvaluesfound, 2)) + ' °C.')\n",
    "print( 'The average air humidity measured at ' + str(howmanyKOSTEUSvaluesfound) + ' weather stations was '\n",
    "     +  str(round(sumofKOSTEUSvalues / howmanyKOSTEUSvaluesfound, 2)) + ' %.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
